{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af060400-e87e-476c-86cc-2530a6008b61",
   "metadata": {},
   "source": [
    "## Maps\n",
    "\n",
    "This is a JupyterLab Notebook summarizing the code I wrote to make some maps of rivers using Python and Geopandas.  But before we get to that, we should start with an outline of the general situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb03710f-6328-482c-94dc-8a8ec86dc606",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "On my machines, running macOS, I have Python 3 installed via Homebrew.\n",
    "\n",
    "It is in the default locations. For the mini, that is ``/usr/local/bin``, while on my new Macbook it is in ``/opt/homebrew/bin``.\n",
    "\n",
    "It seems that these python installations are only used with a virtual environment.\n",
    "\n",
    "Just ``cd`` into a convenient directory and do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e420d18-ab9d-4ff9-bee7-4af0063872c2",
   "metadata": {},
   "source": [
    "`/opt/homebrew/bin/python3 -m venv maps`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582b2da-29ab-4975-8fa6-5bcaeae9c8d0",
   "metadata": {},
   "source": [
    "That sets up a virtual environment with all its supporting files stored in the `maps` directory under whatever directory you were in when you invoked this command.\n",
    "\n",
    "I like working on the desktop so from ``~/Desktop`` do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d28d1-5379-4c4f-843b-f2ad77804a95",
   "metadata": {},
   "source": [
    "`source ~/Programming/maps/bin/activate`\n",
    "\n",
    "`(maps) > `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25935667-da4e-4d0d-b304-3139ccacac0a",
   "metadata": {},
   "source": [
    "That's quite a long command.  It's easy to make an alias in `~/.zshrc` such as `alias activate=\"source ~/Programming/maps/bin/activate\"`.  The prompt will change to `(maps) >`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c1d12-ecde-4450-8fa3-b25bab1d3ee1",
   "metadata": {},
   "source": [
    "Now that the venv is up you can do:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfdf68b-3e99-40f2-b3e7-34bfb15cfd12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "`(maps) > pip install --upgrade pip`\n",
    "\n",
    "`(maps) > python -m pip install matplotlib`\n",
    "\n",
    "`(maps) > python -m pip install geopandas`\n",
    "\n",
    "`(maps) > python -m pip install jupyterlab`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e2cea-5f3e-43da-be43-d683243ca2d0",
   "metadata": {},
   "source": [
    "The correct python will be called simply as ``python``.  Calling `pip` as a module works better for me than calling it directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddc5696-fc2e-49b1-b9a9-76da18397fb4",
   "metadata": {},
   "source": [
    "### Geopandas\n",
    "\n",
    "Pandas is a popular Python module for working with dataframes.  \n",
    "\n",
    "A dataframe is a table with possibly dissimilar columns.  For example, one might have rows of individual amino acids, and columns with various things like molecular weight, hydrophobicity, and so on.\n",
    "\n",
    "A GeoDataFrame (I often call the variable ``gdf``) is a dataframe that contains, among other things, coordinates for geographical objects like polygons and line strings, which can represent state boundaries and rivers.  Geopandas is a popular Python module for this kind of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72c719-603b-4ae9-88be-32472217d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221aad62-abff-4f0e-801a-ea5ae0878aef",
   "metadata": {},
   "source": [
    "We start with a geodataframe containg points along the boundary for selected US states in the Pacific Northwest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f382c-9453-45d5-b76e-2f5f37e6f23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpath = '/Users/telliott/'\n",
    "dbpath += 'Library/CloudStorage/Dropbox/data/'\n",
    "fn = 'OR_WA_ID_MT_WY.shp.zip'\n",
    "nw_states = gpd.read_file(dbpath + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6317f06e-71ad-493b-896b-9e9d454d8a4e",
   "metadata": {},
   "source": [
    "We use various methods to access the individual rows.  The 'NAME' column contains the names of states.  The 'STATE' column contains the FIPS code for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08ab13-1c66-487e-b0e3-07342aeac254",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_states.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6398a7-b61b-4225-ab0c-21fadf7c4e20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nw_states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mnw_states\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mNAME\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'nw_states' is not defined"
     ]
    }
   ],
   "source": [
    "nw_states['NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e4b94d-da5e-4e21-be8c-b56d9836125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_states['STATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6449e6-eb6d-481a-8df6-e59e3e21aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_states['geometry']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738b5f40-0423-4f82-b5ac-3c6569e63e9c",
   "metadata": {},
   "source": [
    "The 'geometry' column contains objects representing the state outlines as POLYGON or MULTIPOLYGON objects.  Washington is a MULTIPOLYGON because it includes a number of islands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a81db-8b5a-4b43-87c6-961c7d01fd47",
   "metadata": {},
   "source": [
    "This dataframe has already been filtered from a larger one containing all 50 states plus DC and Puerto Rico.  Let's start by loading the larger one and showing how to obtain what we have above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df30a0-966e-4294-ac50-66de79fccd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn='gz_2010_us_040_00_5m.zip'\n",
    "gdf = gpd.read_file(dbpath + fn)\n",
    "print(gdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5899d6-f03b-431e-9875-ed9938a33d51",
   "metadata": {},
   "source": [
    "So 52 entries as rows, and each with 6 columns of attributes.  The states we want to select are:  OR, WA, ID, MT, WY.  Here is one way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7706ac-96c0-46d4-a8b2-3c6401964398",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = ['Oregon','Washington','Idaho',\n",
    "    'Montana','Wyoming']\n",
    "sel = gdf['NAME'].isin(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc0c97-aef7-499e-be36-1fe3af9f24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = gdf[sel]\n",
    "print(sub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823ac0d2-d1ad-4a40-ba97-34e7ef870cd0",
   "metadata": {},
   "source": [
    "The ``sel`` variable is a series of boolean values.  The code is otherwise straightforward except for the use of ``isin``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c13485-5425-4865-8f99-9d2887a4ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.iloc[10:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a04825-7867-4cc9-aa2e-21d9de6e44fb",
   "metadata": {},
   "source": [
    "``gdf[sel]`` filters for rows with a value of ``True``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa9b96d-f96c-491d-96f3-8da53527c37d",
   "metadata": {},
   "source": [
    "``iloc`` is a Pandas way of indexing by a numerical index.  It is distinguished from ``loc``, which uses labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92adfbf-7661-4627-9e9a-8683528fd8fc",
   "metadata": {},
   "source": [
    "### ``apply``\n",
    "\n",
    "You can supply either a named function or a ``lambda`` expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05550da7-f764-4efe-b84b-ebb76189e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = gdf['NAME'].apply(lambda r: r in L)\n",
    "sub = gdf[sel]\n",
    "print(gdf.shape, sub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b5c90b-ef53-40ed-b5e3-19b0df379104",
   "metadata": {},
   "source": [
    "And yet a third way is to construct a series of logical expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b588e2e-bd5b-4b2b-9a2f-f649bf831b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OR = gdf['NAME'] == 'Oregon'\n",
    "WA = gdf['NAME'] == 'Washington'\n",
    "ID = gdf['NAME'] == 'Idaho'\n",
    "MT = gdf['NAME'] == 'Montana'\n",
    "WY = gdf['NAME'] == 'Wyoming'\n",
    "sub = gdf[OR | WA | ID | MT | WY]\n",
    "print(gdf.shape, sub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a21366b-b160-47a4-854c-64cf23fcf762",
   "metadata": {},
   "source": [
    "Since we have ``matplotlib``, let's plot the data.  A very simple approach is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b3e92c-71d8-47ff-b4d2-e3ff3305aea1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nw_states.boundary.plot()\n",
    "ofn = 'example.png'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf92cb3-8136-4a06-a4a0-66ea95bd94a1",
   "metadata": {},
   "source": [
    "To save the plot in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb214e-76b0-49dc-b207-c30d28e3a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ofn = 'example.png'\n",
    "plt.savefig(ofn,dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6b68b-c15a-4872-9ae7-8892fd12f1fa",
   "metadata": {},
   "source": [
    "It would be nice to have some labels. Let's add a column to the data with the two letter abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ebc77c-d451-469d-b19f-4d9c7e96030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = ['OR','WA','ID','MT','WY']\n",
    "nw_states = nw_states.assign(abbrev = L)\n",
    "nw_states['abbrev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c90029-5fc5-4d0a-ade2-6b0ca931b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(e):\n",
    "    return e.representative_point().coords[:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8804285-dcd3-4d3f-870b-7390e7d43112",
   "metadata": {},
   "source": [
    "The ``[0]`` at the end is because the coordinates are like ``[(x,y)]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614c143-4339-43e4-a8ec-859d5fed1906",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_states['coords'] = nw_states['geometry'].apply(f)\n",
    "nw_states['coords']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764f577c-3aac-4875-8836-cc420b666142",
   "metadata": {},
   "source": [
    "One can use ``iterrows`` to iterate through the data.  We adjust the position of the label for Idaho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca9d56e-652a-4ebd-9117-27a61ade8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_states.boundary.plot()\n",
    "for i,row in nw_states.iterrows():\n",
    "    x,y = row['coords']\n",
    "    if row['NAME'] == 'Idaho':\n",
    "        y -= 1\n",
    "    plt.annotate(text=row['NAME'],\n",
    "        xy=(x,y),\n",
    "        horizontalalignment='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd15ba8-5e51-4d12-b456-8d63eb485699",
   "metadata": {},
   "source": [
    "Let's add a river.  The original data is in a file named 'North_America_Lakes_and_Rivers.zip'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38ece2-ffbc-4d6f-ae1b-632326db2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'nw_rivers.shp.zip'\n",
    "nw_rivers = gpd.read_file(dbpath + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cfc98b-70d9-4b25-bb77-627aa9c29b67",
   "metadata": {},
   "source": [
    "First we have to match the coordinate representation system (CRS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9959675c-e5a0-461d-ab78-1a04be07659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_states.crs\n",
    "nw_rivers.crs\n",
    "mycrs = nw_rivers.crs\n",
    "nw_states.to_crs(mycrs,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1176828a-7978-4e32-a7a1-5f5f140d7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel(s):\n",
    "    return nw_rivers['NameEn'].str.contains(s)\n",
    "\n",
    "Snake = nw_rivers[sel('Snake')]\n",
    "\n",
    "# remove some small waterways\n",
    "Snake = Snake[Snake['LengthKm'] > 200]\n",
    "\n",
    "ax = nw_states.boundary.plot(\n",
    "    figsize=(9, 9),color='blue')\n",
    "nw_states.plot(ax=ax,color='b',alpha=0.05)\n",
    "Snake.plot(ax=ax,color='red')\n",
    "plt.savefig('snake.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfcc5ea-4170-44f9-b0c4-fb59f01ef6b6",
   "metadata": {},
   "source": [
    "There is one more item to be cleaned up --- the small object at the bottom of Wyoming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fcfdf3-d39e-4f15-95d2-3fd6fde930d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Snake['NameEn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc454f20-04eb-40ad-ad3e-d3ea601b66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'Little Snake River'\n",
    "Snake = Snake[Snake['NameEn'] != t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e9a61-0b34-48f4-8c89-b2bd69fcbb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Snake['NameEn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482841da-926b-437e-99d9-bc0b2ff35815",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = nw_states.boundary.plot(\n",
    "    figsize=(9, 9),color='blue')\n",
    "nw_states.plot(ax=ax,color='b',alpha=0.05)\n",
    "Snake.plot(ax=ax,color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac4a1e-657b-4a72-821d-0138d88056ba",
   "metadata": {},
   "source": [
    "To convert this notebook to html do:\n",
    "\n",
    "`jupyter nbconvert --execute --to html explore.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c4e3b-deac-44d8-ad29-fab9a295eb2a",
   "metadata": {},
   "source": [
    "Note:  the original rivers data is quite a large file.  I filtered it for data in a restricted geographic region and then saved it as a shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272830f-8789-4763-ac94-cb20096bbcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'North_America_Lakes_and_Rivers.zip'\n",
    "na_rivers = gpd.read_file(dbpath + fn)\n",
    "na_rivers = na_rivers.to_crs(mycrs)\n",
    "nw_rivers = na_rivers.overlay(nw_states, \n",
    "    how='intersection')\n",
    "\n",
    "nw_rivers.to_file(\n",
    "    filename='nw_rivers.shp.zip',\n",
    "    driver='ESRI Shapefile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b559250-a9f7-45ca-a99f-5f6b3e032975",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rivers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777ea05-a3a4-4cb6-86a4-2900e8680acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_rivers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b2de85-8e4b-41b4-9827-d76e113397ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_rivers.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61bff57-f320-487c-8b5b-79d7bbf13855",
   "metadata": {},
   "source": [
    "I've picked up some extra columns.  I forget how this happened, at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db399f9c-2819-4f5c-9bed-fa3fd3a6a8e9",
   "metadata": {},
   "source": [
    "One last thing.  Various basemaps are available.  Sometimes it works:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49790c16-7122-46fd-aa6a-27134a99f5d8",
   "metadata": {},
   "source": [
    "<img src='9 results/annotated.png' width='800' height='400' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c89c8-3d78-4b79-a84b-235edceec3ec",
   "metadata": {},
   "source": [
    "Sometimes it doesn't work.  Something about the zoom level.  The code is pretty trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce842b-3ce4-4237-881f-ac8471a7cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as cx\n",
    "\n",
    "dbpath = '/Users/telliott/Library/CloudStorage/Dropbox/data/'\n",
    "fn = 'OR_WA_ID_MT_WY.shp.zip'\n",
    "gdf = gpd.read_file(dbpath+fn)\n",
    "ID = gdf[gdf['NAME'] == 'Idaho']\n",
    "ax=ID.boundary.plot(color='b',figsize=(6,6))\n",
    "cx.add_basemap(ax,source =cx.providers.OpenTopoMap,crs=ID.crs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9598e2-1764-4c70-a83e-422b7b25eb22",
   "metadata": {},
   "source": [
    "You do have to match the CRS or change (warp) it for the basemap.  Here is a more extensive example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d6eb5-4de0-4fcf-b73c-a6865d30e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as cx\n",
    "\n",
    "dbpath = '/Users/telliott/'\n",
    "dbpath += 'Library/CloudStorage/Dropbox/data/'\n",
    "fn = 'OR_WA_ID_MT_WY.shp.zip'\n",
    "gdf = gpd.read_file(dbpath + fn)\n",
    "\n",
    "# CRS \n",
    "# OpenTopoMap uses Web Mercator ('EPSG:3857')\n",
    "# gdf is NAD 83 ('EPSG:4269')\n",
    "my_crs = 'EPSG:4269'\n",
    "\n",
    "ID = gdf[gdf['NAME'] == 'Idaho']\n",
    "MT = gdf[gdf['NAME'] == 'Montana']\n",
    "\n",
    "fn = 'nw_rivers.shp.zip'\n",
    "nw_rivers = gpd.read_file(dbpath + fn)\n",
    "nw_rivers = nw_rivers.to_crs(my_crs)\n",
    "\n",
    "# restrict the rivers to a bounding box\n",
    "xmin, ymin, xmax, ymax = -116, 44, -112, 48\n",
    "from shapely.geometry import Polygon\n",
    "poly = Polygon([(xmin,ymin),(xmax,ymin),(xmax,ymax),(xmin,ymax)])\n",
    "gs = gpd.GeoSeries(poly)\n",
    "bbox = gpd.GeoDataFrame({'geometry': gs})\n",
    "bbox = bbox.set_crs(my_crs)\n",
    "sub = nw_rivers.overlay(bbox, how='intersection')\n",
    "\n",
    "# continental divide\n",
    "fn = 'Continental_Divide-Pacific_Atlantic.zip'\n",
    "cdiv = gpd.read_file(dbpath + fn)\n",
    "cdiv = cdiv.to_crs('EPSG:4269')\n",
    "cdiv = cdiv.overlay(gdf, how='intersection')\n",
    "\n",
    "ax=ID.boundary.plot(color='k',figsize=(6,6))\n",
    "cdiv.plot(ax=ax,color='r')\n",
    "bbox.boundary.plot(ax=ax,color='gray')\n",
    "sub.plot(ax=ax,color='b',lw=0.6)\n",
    "\n",
    "cx.add_basemap(ax,\n",
    "    source =cx.providers.OpenTopoMap,\n",
    "    crs=ID.crs)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7635d1c7-b7bf-4097-a01e-f9d20b500748",
   "metadata": {},
   "source": [
    "The code illustrates the use of a bounding box and the `.cx` method of a gdf.  I've followed the convention for contextily and imported the name as `cx`, even though this could be confusing.  Since the method is qualified, Python keeps it all straight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1abf55d-7184-46ff-b88d-a74abec2b487",
   "metadata": {},
   "source": [
    "The red line is the continental divide.  This makes it easier to understand which way the rivers must flow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
